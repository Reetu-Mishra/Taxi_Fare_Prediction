{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875bba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03716964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"HiveTableCreation\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8e7a9",
   "metadata": {},
   "source": [
    "# Creating hive table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68a5756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS taxi_fare_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2bc493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        databaseName|\n",
      "+--------------------+\n",
      "|             default|\n",
      "|             futurex|\n",
      "|taxi_fare_prediction|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994b5176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----------------------------------------------------------------+\n",
      "|database_description_item|database_description_value                                       |\n",
      "+-------------------------+-----------------------------------------------------------------+\n",
      "|Database Name            |taxi_fare_prediction                                             |\n",
      "|Description              |                                                                 |\n",
      "|Location                 |hdfs://localhost:9000/user/hive/warehouse/taxi_fare_prediction.db|\n",
      "|Properties               |                                                                 |\n",
      "+-------------------------+-----------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE DATABASE EXTENDED taxi_fare_prediction\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1975deea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE taxi_fare_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0383ef5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS taxi_trips_data\")\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE taxi_trips_data(\n",
    "    VendorID INT,\n",
    "    tpep_pickup_datetime TIMESTAMP,\n",
    "    tpep_dropoff_datetime TIMESTAMP,\n",
    "    passenger_count INT,\n",
    "    trip_distance FLOAT,\n",
    "    RatecodeID INT,\n",
    "    store_and_fwd_flag STRING,\n",
    "    PULocationID INT,\n",
    "    DOLocationID INT,\n",
    "    payment_type STRING,\n",
    "    fare_amount FLOAT,    \n",
    "    extra FLOAT,\n",
    "    mta_tax FLOAT,\n",
    "    tip_amount FLOAT,\n",
    "    tolls_amount FLOAT,\n",
    "    improvement_surcharge FLOAT,\n",
    "    total_amount FLOAT,\n",
    "    congestion_surcharge FLOAT\n",
    ")\n",
    "\n",
    "USING CSV\n",
    "\n",
    "OPTIONS (\n",
    "\n",
    "    header 'true',\n",
    "\n",
    "    inferSchema 'true',\n",
    "\n",
    "    delimiter ','\n",
    "\n",
    ")\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "439aadfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       2| 2019-05-01 00:05:26|  2019-05-01 00:05:34|              1|          0.0|         1|                 N|         193|         193|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|\n",
      "|       1| 2019-05-01 00:27:58|  2019-05-01 00:30:26|              1|         10.6|         1|                 N|         106|         106|           1|        2.5|  0.5|    0.5|       1.2|         0.0|                  0.3|         5.0|                 0.0|\n",
      "|       1| 2019-05-01 00:24:48|  2019-05-01 00:28:04|              1|          0.5|         1|                 N|          79|          79|           1|        4.5|  3.0|    0.5|      1.66|         0.0|                  0.3|        9.96|                 2.5|\n",
      "|       2| 2019-05-01 00:16:06|  2019-05-01 00:42:58|              6|         7.99|         1|                 N|         148|         151|           1|       27.0|  0.5|    0.5|      6.16|         0.0|                  0.3|       36.96|                 2.5|\n",
      "|       2| 2019-05-01 00:08:30|  2019-05-01 00:14:09|              1|         1.07|         1|                 N|          50|          48|           2|        6.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         9.8|                 2.5|\n",
      "|       1| 2019-05-01 00:56:16|  2019-05-01 01:09:03|              1|          4.1|         1|                 N|          68|          75|           1|       13.5|  3.0|    0.5|      3.45|         0.0|                  0.3|       20.75|                 2.5|\n",
      "|       2| 2019-05-01 00:28:51|  2019-05-01 00:30:37|              1|         0.78|         1|                 N|         237|         236|           1|        4.0|  0.5|    0.5|      1.56|         0.0|                  0.3|        9.36|                 2.5|\n",
      "|       2| 2019-05-01 00:05:07|  2019-05-01 00:13:15|              2|         2.86|         1|                 N|         234|         231|           1|        9.5|  0.5|    0.5|      3.32|         0.0|                  0.3|       16.62|                 2.5|\n",
      "|       2| 2019-05-01 00:16:45|  2019-05-01 00:25:52|              1|         1.94|         1|                 N|         163|         186|           1|        9.0|  0.5|    0.5|      2.56|         0.0|                  0.3|       15.36|                 2.5|\n",
      "|       1| 2019-05-01 00:58:43|  2019-05-01 01:04:17|              1|          0.7|         1|                 N|         236|         236|           1|        5.5|  2.5|    0.5|       0.5|         0.0|                  0.3|         9.3|                 2.5|\n",
      "|       2| 2019-05-01 00:16:13|  2019-05-01 00:22:33|              2|         0.84|         1|                 N|         161|         230|           2|        6.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         9.8|                 2.5|\n",
      "|       1| 2019-05-01 00:20:46|  2019-05-01 00:50:42|              2|          9.4|         1|                 N|          68|          95|           1|       30.0|  3.0|    0.5|       5.0|        6.12|                  0.3|       44.92|                 2.5|\n",
      "|       1| 2019-05-01 00:58:32|  2019-05-01 01:10:06|              1|          3.0|         1|                 N|         163|         249|           1|       11.5|  3.0|    0.5|      3.05|         0.0|                  0.3|       18.35|                 2.5|\n",
      "|       2| 2019-05-01 00:44:56|  2019-05-01 01:02:14|              1|          7.0|         1|                 N|         231|         262|           1|       22.0|  0.5|    0.5|       3.5|         0.0|                  0.3|        29.3|                 2.5|\n",
      "|       1| 2019-05-01 00:56:25|  2019-05-01 01:15:12|              1|          5.2|         1|                 N|         237|         116|           1|       17.5|  3.0|    0.5|       4.0|         0.0|                  0.3|        25.3|                 2.5|\n",
      "|       2| 2019-05-01 00:43:37|  2019-05-01 00:53:05|              1|         1.28|         1|                 N|         233|          48|           1|        8.0|  0.5|    0.5|       3.7|         0.0|                  0.3|        15.5|                 2.5|\n",
      "|       1| 2019-05-01 00:48:48|  2019-05-01 00:53:22|              2|          1.0|         1|                 N|         230|          68|           1|        5.5|  3.0|    0.5|      1.85|         0.0|                  0.3|       11.15|                 2.5|\n",
      "|       2| 2019-05-01 00:33:32|  2019-05-01 00:38:29|              2|         1.03|         1|                 N|         236|         236|           2|        6.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         9.8|                 2.5|\n",
      "|       2| 2019-05-01 00:22:09|  2019-05-01 00:35:05|              1|          2.5|         1|                 N|         142|         164|           1|       11.0|  0.5|    0.5|      2.96|         0.0|                  0.3|       17.76|                 2.5|\n",
      "|       1| 2019-05-01 00:27:08|  2019-05-01 00:45:52|              1|          3.7|         1|                 N|         137|          66|           2|       16.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        19.8|                 2.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"Final_Project/taxi_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "901b0328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "729071ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1681873, 18)\n"
     ]
    }
   ],
   "source": [
    "row_count = df.count()\n",
    "column_count = len(df.columns)\n",
    "print('Shape: ',(row_count,column_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a2cdb5",
   "metadata": {},
   "source": [
    "# Dropping nulls, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a078c16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1681873\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# Specifying irrelevant columns\n",
    "columns_to_drop = ['VendorID','passenger_count', 'store_and_fwd_flag', 'RatecodeID', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'payment_type', 'trip_type', 'congestion_surcharge']\n",
    "\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "df_new = df.drop(*columns_to_drop)\n",
    "\n",
    "print(df_new.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0f3c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.na.drop()\n",
    "df_new = df_new.filter(~(col(\"total_amount\") == \"NaN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d767fd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|min_total|max_total|\n",
      "+---------+---------+\n",
      "|   -300.8|  90000.0|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "\n",
    "# Compute min and max\n",
    "df_new.select(\n",
    "    min(\"total_amount\").alias(\"min_total\"),\n",
    "    max(\"total_amount\").alias(\"max_total\")\n",
    "    \n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a646ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|min_total|max_total|\n",
      "+---------+---------+\n",
      "|    -29.2|    202.7|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "\n",
    "# Compute min and max\n",
    "df_new.select(\n",
    "    min(\"trip_distance\").alias(\"min_total\"),\n",
    "    max(\"trip_distance\").alias(\"max_total\")\n",
    "    \n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6040fcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with total_amount <= 0: 3714\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where total_amount < 0\n",
    "negative_total_amount_df = df_new.filter(df_new.total_amount <= 0)\n",
    "\n",
    "# Count how many such rows exist\n",
    "amount_negative = negative_total_amount_df.count()\n",
    "\n",
    "print(\"Number of rows with total_amount <= 0:\", amount_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fa31688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with trip_distance <= 0: 15191\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where total_amount < 0\n",
    "negative_trip_distance_df = df_new.filter(df_new.trip_distance <= 0)\n",
    "\n",
    "# Count how many such rows exist\n",
    "distance_negative = negative_trip_distance_df.count()\n",
    "\n",
    "print(\"Number of rows with trip_distance <= 0:\", distance_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cac124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[df_new['total_amount'] > 0]\n",
    "df_new = df_new[df_new['trip_distance'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "372d565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[~df_new['PULocationID'].isin([264, 265]) & ~df_new['DOLocationID'].isin([264, 265])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea667cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1644242"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2bfdd",
   "metadata": {},
   "source": [
    "# Creating time category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b161594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, dayofmonth, month, when, col\n",
    "\n",
    "# Extract hour, day, and month from pickup time\n",
    "df_new = df_new.withColumn(\"hour\", hour(col(\"tpep_pickup_datetime\")))\n",
    "df_new = df_new.withColumn(\"day\", dayofmonth(col(\"tpep_pickup_datetime\")))\n",
    "df_new = df_new.withColumn(\"month\", month(col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "# Categorize time into parts of day (label)\n",
    "df_new = df_new.withColumn(\n",
    "    \"time_category\",\n",
    "    when((col(\"hour\") >= 0) & (col(\"hour\") < 6), \"Early Morning\")\n",
    "    .when((col(\"hour\") >= 6) & (col(\"hour\") < 12), \"Morning\")\n",
    "    .when((col(\"hour\") >= 12) & (col(\"hour\") < 16), \"Afternoon\")\n",
    "    .when((col(\"hour\") >= 16) & (col(\"hour\") < 20), \"Evening\")\n",
    "    .otherwise(\"Night\")\n",
    ")\n",
    "\n",
    "# Create time category encoding\n",
    "df_new = df_new.withColumn(\n",
    "    \"time_category_encoded\",\n",
    "    when((col(\"hour\") >= 0) & (col(\"hour\") < 6), 1)\n",
    "    .when((col(\"hour\") >= 6) & (col(\"hour\") < 12), 2)\n",
    "    .when((col(\"hour\") >= 12) & (col(\"hour\") < 16), 3)\n",
    "    .when((col(\"hour\") >= 16) & (col(\"hour\") < 20), 4)\n",
    "    .otherwise(5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49da1312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.filter(col(\"time_category_encoded\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9de00659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[['time_category_encoded','month', 'day', 'PULocationID', 'DOLocationID', 'trip_distance', 'total_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e5f1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.orderBy(\"month\",\"day\",\"time_category_encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29f8f1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+---+------------+------------+-------------+------------+\n",
      "|time_category_encoded|month|day|PULocationID|DOLocationID|trip_distance|total_amount|\n",
      "+---------------------+-----+---+------------+------------+-------------+------------+\n",
      "|                    1|    1|  1|         238|         244|         5.25|        17.3|\n",
      "|                    1|    1|  1|          79|         129|         8.45|       33.06|\n",
      "|                    1|    1|  1|         144|         261|          1.7|       11.15|\n",
      "|                    1|    1|  1|          75|         229|         2.84|       13.56|\n",
      "|                    1|    1|  1|         231|         162|          4.9|       17.91|\n",
      "|                    1|    1|  1|         249|         186|          2.5|       15.96|\n",
      "|                    1|    1|  1|         125|         238|         10.7|        47.3|\n",
      "|                    1|    1|  1|         140|         262|          1.0|        7.82|\n",
      "|                    1|    1|  1|         142|         238|          1.8|       12.95|\n",
      "|                    1|    1|  1|         262|          79|          5.2|       21.96|\n",
      "|                    1|    1|  1|         151|         239|          1.2|         7.8|\n",
      "|                    1|    1|  1|         209|         231|          0.8|         9.3|\n",
      "|                    1|    1|  1|          90|          50|          2.0|       15.95|\n",
      "|                    1|    1|  1|         142|         246|         1.91|        11.8|\n",
      "|                    1|    1|  1|          68|         239|         3.07|       19.75|\n",
      "|                    1|    1|  1|         255|          37|         1.52|       11.16|\n",
      "|                    1|    1|  1|         238|         151|          0.7|         8.5|\n",
      "|                    1|    1|  1|          79|         263|          4.1|        18.3|\n",
      "|                    1|    1|  1|         107|         229|          1.7|        11.8|\n",
      "|                    1|    1|  1|         113|         249|          0.6|        8.15|\n",
      "+---------------------+-----+---+------------+------------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a708430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1644242"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38dab6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3099de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = df_new.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbe199e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_category_encoded</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>263</td>\n",
       "      <td>4.1</td>\n",
       "      <td>18.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>229</td>\n",
       "      <td>1.7</td>\n",
       "      <td>11.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>238</td>\n",
       "      <td>1.8</td>\n",
       "      <td>12.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_category_encoded  month  day  PULocationID  DOLocationID  \\\n",
       "0                      1      1    1           238           151   \n",
       "1                      1      1    1            79           263   \n",
       "2                      1      1    1           107           229   \n",
       "3                      1      1    1           142           238   \n",
       "4                      1      1    1           140           262   \n",
       "\n",
       "   trip_distance  total_amount  \n",
       "0            0.7          8.50  \n",
       "1            4.1         18.30  \n",
       "2            1.7         11.80  \n",
       "3            1.8         12.95  \n",
       "4            1.0          7.82  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43edb437",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data.to_csv(\"/home/talentum/preprocessed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005a348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
